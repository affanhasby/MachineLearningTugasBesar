# -*- coding: utf-8 -*-
"""Malin Tugas Besar Affan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TAzhX2ja0pTCAkITBYGFabVlYmUO0iyJ
"""

import pandas as pd
import numpy as np
from collections import Counter
from numpy.random import rand
import math
import random

fiture = ["attacking_crossing","attacking_finishing","attacking_heading_accuracy","attacking_short_passing","attacking_volleys",
            "skill_dribbling","skill_curve","skill_fk_accuracy","skill_long_passing","skill_ball_control",
            "movement_acceleration","movement_sprint_speed","movement_agility","movement_reactions","movement_balance",
            "power_shot_power","power_jumping","power_stamina","power_strength","power_long_shots",
            "mentality_aggression","mentality_interceptions","mentality_positioning","mentality_vision","mentality_penalties",
            "defending_marking","defending_standing_tackle","defending_sliding_tackle",
            "goalkeeping_diving","goalkeeping_handling","goalkeeping_kicking","goalkeeping_positioning","goalkeeping_reflexes",
]
depan = ["LS","ST","RS","LW","LF","CF","RF", "RW"]
tengah = ["LAM","CAM","RAM","LM","LCM","CM","RCM","RM"]
belakang = ["LWB","LDM","CDM","RDM","RWB","LB","LCB", "CB" , "RCB" , "RB", "GK"]

labelData = {"depan" : depan ,"tengah" : tengah ,"belakang" : belakang}

def read():
  data = []
  output = []

  df = pd.read_csv("fifa20.csv")
  for j in range(0 , len(df)):
    data.append([]);
    #masukkan data dari feature ke array
    for fitur in fiture:
      data[j].append(df[fitur][j]/100.0)

    pos = (df["player_positions"][j].replace(" ","")).split(",")
    availablePos = []
    for p in pos:
      for key in labelData:
        if p in labelData[key]:
            availablePos.append(key)
            break
    output.append(availablePos);
  return data , output

"""**Klasifikasi KNN**"""

class Knn:
  clusters = []
  countn = 1
  def __init__(self,clusters,countn):
    self.clusters = clusters
    self.countn = countn

  def pdk(self , vec):
    mins = np.zeros(len(self.clusters))
    for i in range(0 , len(self.clusters)):
      mins[i] = jarak(self.clusters[i]["centroid"] , vec)
    
    nlabel = mins.argsort()[:self.countn]
    count = Counter()
    for x in nlabel:
      pos = self.clusters[x]["label"]
      count[pos] += 1
    
    max_key = max(count, key=lambda k: count[k])
    return max_key

"""**K-Means Clustering**"""

def jarak(vec1,vec2):
  sums = 0;
  for i in range(0,len(vec1)):
    sums += (vec1[i]-vec2[i])**2
  return math.sqrt(sums)

class KMeans:

  clusters = None

  def __init__(self,clusters_count , features):
    self.clusters = []
    for i in range(0 , clusters_count):
      self.clusters.append( features[random.randint(0,len(features))] )
    #self.clusters = rand( clusters_count , feature_len)

  def fit(self,featureInputs):
    temp = np.zeros( (len(self.clusters) , len(self.clusters[0]) ) );

    while((temp == self.clusters).all()):
      temp = self.clusters;
      self.clusters = self.iterateCluster(featureInputs)

    return 0

  def iterateCluster(self,featureInputs):
    
    counter = np.zeros( len(self.clusters) )
    clusters_next = np.zeros( (len(self.clusters) , len(self.clusters[0]) ) )
    temp_idx_feature = []

    for feature in featureInputs:
      dist = -1
      idx = -1
      for i in range(0 , len( self.clusters )):
        delta = jarak(self.clusters[i] ,feature)  #( sum( ( np.array(clusters[i]) - np.array(feature) )**2 ) )**0.5
        if(delta < dist or dist == -1):
          dist = delta
          idx = i

      temp_idx_feature.append([idx, feature])
      counter[idx] += 1 
    
    for tempIF in temp_idx_feature:
      clusters_next[tempIF[0]] += np.array(tempIF[1])/(1.0*counter[tempIF[0]])

    return clusters_next

  def generateCluster(self,vec , idx):
    cluster = {
        "centroid" : vec,
        "element_idx" : idx,
        "posisi_c" : Counter(),
        "label" : ""
    }
    return cluster

  def getClusters(self,featureInputs , labelOutput):
    output = []
    print(len(self.clusters))
    for c in self.clusters:
      output.append(self.generateCluster(c , []) )

    for k in range(0 , len(featureInputs)):
      dist = -1
      idx = -1
      for i in range(0 , len( self.clusters )):
        delta = jarak(self.clusters[i] ,featureInputs[k])  #( sum( ( np.array(clusters[i]) - np.array(feature) )**2 ) )**0.5
        if(delta < dist or dist == -1):
          dist = delta
          idx = i
      
      output[idx]['element_idx'].append(k)
      lisLabel = list(dict.fromkeys(labelOutput[k]))
      for L in lisLabel:
        output[idx]['posisi_c'][L] += 1 
      
      #print(output[idx])

    #print(output)
    for i in range(0, len(output)):
      #print(i , output[i]['posisi_c'])
      max_key = max(output[i]['posisi_c'], key=lambda k: output[i]['posisi_c'][k])
      output[i]['label'] = max_key

    return output

def akurasi(Clasifier , DataUji , DataAnswer):
  corr = [];
  for i in range(0,len(DataUji)):
    result = Clasifier.pdk(DataUji[i])
    if (result in dataAnswer[i]):
      corr.append(1)
    else:
      corr.append(0)

  return (sum(corr)/len(corr))

data, dataAnswer = read();

kmeans = KMeans(7, data[0:300])
kmeans.fit(data[0:300])

global_clusters_KMeans = kmeans.getClusters(data[0:100] , dataAnswer[0:100] )
global_clusters_KMeans

KMeans = Knn(global_clusters_KMeans,3)
print("KMeans: ",akurasi(KMeans,data[0:17000],dataAnswer[0:17000])*100)

